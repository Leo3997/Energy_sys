import socket
import json
import threading
import pickle
import numpy as np
import time
from flask import Flask, jsonify, send_file, request, Response
from flask_cors import CORS
from dotenv import load_dotenv
import os

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# --- æ–°å¢ 1: å¼•å…¥ InfluxDB åº“ ---
from influxdb_client import InfluxDBClient, Point, WriteOptions
from influxdb_client.client.write_api import SYNCHRONOUS, ASYNCHRONOUS
# --- æ–°å¢ 5: å¼•å…¥ Flask-SocketIO ---
from flask_socketio import SocketIO, emit
import eventlet

# --- æ–°å¢ Imports for Realtime Monitoring ---
import sys
import os
from datetime import datetime
# Ensure we can import from local directory
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from energy_model.influx_connector import InfluxConnector
from energy_model.optimization import EnergyOptimizer
from energy_model.optimization import EnergyOptimizer
from energy_model.lstm_forecasting import LSTMForecaster
from energy_model.optimization import EnergyOptimizer
from energy_model.mysql_db import MySQLDatabase # [NEW] MySQL Support
from energy_model.settings import settings # [NEW] Settings Support
import pandas as pd
import io
import csv

# --- æ–°å¢ 2: è¿œç¨‹æ•°æ®åº“é…ç½® ---
# è¯·å°†ä¸‹é¢çš„ Token æ›¿æ¢ä¸ºä½ è¿œç¨‹æ•°æ®åº“ (115.120.248.123) ä¸Šçš„çœŸå® Token
INFLUX_URL = "http://115.120.248.123:8086"
INFLUX_TOKEN = "dev-admin-token-123456"  
INFLUX_ORG = "dls"                         
INFLUX_BUCKET = "energy_save_data"      

# --- Realtime Monitoring Config (from realtime_monitoring.py) ---
MONITOR_URL = "http://1.94.121.255:8086"
MONITOR_TOKEN = "K-xsdqIdqS0CaEl2cj2nHqGmgXv6A6EjQ7TuZhHd6d15Ns9LqNYsVveX9lJzob7LT-Q0pfylKpiXdDbPEy87JQ=="
MONITOR_BUCKET = "energy"
MONITOR_ORG = "fengtian"
# TARGET_DEVICE å·²ç§»è‡³ GLOBAL_STATE['current_device']

# --- MySQL Config ---
MYSQL_HOST = "115.120.248.123"
MYSQL_USER = "root"
MYSQL_PASS = "rootpassword"
MYSQL_DB = "energy"
mysql_db = None # Global instance

# å…¨å±€å®¢æˆ·ç«¯å˜é‡
influx_client = None
write_api = None

import requests # Ensure requests is imported
QWEN_API_KEY = os.getenv('QWEN_API_KEY', '')



try:
    from predict_baseline import EnergyBaselinePredictor
except ImportError:
    print("âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ° predict_baseline.pyï¼ŒåŸºçº¿é¢„æµ‹åŠŸèƒ½å°†ä¸å¯ç”¨")
    EnergyBaselinePredictor = None

# --- é…ç½® ---
HOST = '0.0.0.0'    # å»ºè®®æ”¹ä¸º 0.0.0.0 ä»¥ä¾¿å…è®¸å¤–éƒ¨è®¿é—®
PORT = 8012        
HTTP_PORT = 8011    

# ... (Global State, Price, Injection Config ä¿æŒä¸å˜) ...
GLOBAL_STATE = {
    "devices": {},  
    "current_device": "energy*1*1",  # å½“å‰ç›‘æ§çš„è®¾å¤‡IDï¼Œå¯åŠ¨æ€åˆ‡æ¢
    "energy_stats": {
        "total_savings_kwh": 0.0,
        "total_savings_elec_cost": 0.0,
        "total_savings_oil_liters": 0.0,
        "total_savings_cost": 0.0,
        "current_total_power": 0.0,
        "baseline_total_power": 0.0
    },
    "monitor_context": {},
    "command_queues": {} # { "device_ip": [ {"action": "...", ...} ] }
}
GLOBAL_STATE['logs'] = []

def add_system_log(event_type, message, details=None, device_ip=None, device_type=None):
    """Add a log entry, emit via WebSocket, and save to MySQL."""
    log_entry = {
        "timestamp": datetime.now().strftime('%H:%M:%S'),
        "event_type": event_type,
        "message": message,
        "details": details or {}
    }
    # Keep last 50 logs
    GLOBAL_STATE['logs'].insert(0, log_entry)
    if len(GLOBAL_STATE['logs']) > 50:
        GLOBAL_STATE['logs'].pop()
    
    socketio.emit('system_log_new', log_entry)

    # [NEW] Save to MySQL
    if mysql_db:
        mysql_db.insert_event(
            device_ip or "SYSTEM", 
            device_type or "SERVER", 
            event_type, 
            message, 
            details
        )

# Constants are now managed by settings.py
# ELECTRICITY_PRICE = 0.5
# OIL_PRICE = 20.0
# ...

PRODUCTION_ORDERS = {
    "127.0.0.1": {
        "diameter": 30,
        "needles": 3200,
        "yarn": "Polyester",
        "structure": "Jacquard",
        "rpm": 25
    }
}

# ... (LubricationAI_RL, TensionAI_RL ç±»ä¿æŒä¸å˜) ...
class LubricationAI_RL:
    def __init__(self):
        self.load_model()
        self.cooldown = 0
        self.inject_count = 0 
        
    def load_model(self):
        self.model_path = "q_brain.pkl"
        self.last_mtime = 0
        try:
            if os.path.exists(self.model_path):
                self.last_mtime = os.path.getmtime(self.model_path)
                with open(self.model_path, "rb") as f:
                    self.q_table = pickle.load(f)
                print("ğŸ§  [LubAI] Model Loaded/Reloaded")
            else:
                self.q_table = None
        except:
             self.q_table = None

    def check_reload(self):
        if os.path.exists(self.model_path):
            mtime = os.path.getmtime(self.model_path)
            if mtime > self.last_mtime:
                print("ğŸ”„ [LubAI] Detecting model change, reloading...")
                self.load_model()

    # ... (analyze æ–¹æ³•ä¿æŒä¸å˜) ...
    def analyze(self, data):
        self.check_reload() # [NEW] Check before analyze
        # (ä¸ºäº†èŠ‚çœç¯‡å¹…ï¼Œè¿™é‡Œçœç•¥ä¸­é—´ä»£ç ï¼Œè¯·ä¿æŒåŸæ ·)
        if self.cooldown > 0:
            self.cooldown -= 1
            return None
        curr = data.get('current_a', 10.0)
        temp = data.get('temperature_c', 40.0)
        if temp > 55.0 or curr > 13.0:
             self.cooldown = 5
             self.inject_count += 1
             return {"action": "INJECT", "msg": "ğŸ”¥ å¼ºåˆ¶ä¿æŠ¤"}
        if self.q_table is not None:
            curr_idx = int(min(9, max(0, (curr - 9.0) * 2)))
            temp_idx = int(min(9, max(0, (temp - 25.0) / 5)))
            if np.argmax(self.q_table[curr_idx, temp_idx]) == 1:
                self.cooldown = 5
                self.inject_count += 1
                return {"action": "INJECT", "msg": "ğŸ§  RLå†³ç­–å–·æ²¹"}
        return {"action": "MONITOR", "msg": "Running"}

    def force_cooldown(self, steps):
        self.cooldown = max(self.cooldown, steps)

class TensionAI_RL:
    def __init__(self):
        self.load_model()
        self.optimize_count = 0

    def load_model(self):
        self.model_path = "tension_q_brain.pkl"
        self.last_mtime = 0
        try:
            if os.path.exists(self.model_path):
                self.last_mtime = os.path.getmtime(self.model_path)
                with open(self.model_path, "rb") as f:
                    self.q_table = pickle.load(f)
                print("ğŸ§  [TensionAI] Model Loaded/Reloaded")
            else:
                self.q_table = None
        except:
             self.q_table = None

    def check_reload(self):
        if os.path.exists(self.model_path):
            mtime = os.path.getmtime(self.model_path)
            if mtime > self.last_mtime:
                print("ğŸ”„ [TensionAI] Detecting model change, reloading...")
                self.load_model()

    # ... (analyze æ–¹æ³•ä¿æŒä¸å˜) ...
    def analyze(self, data):
        self.check_reload()
        # (ä¿æŒåŸæ ·)
        tension = data.get('tension', 3.0)
        yarn_pct = data.get('yarn_pct', 100.0)
        yarn_idx = int((yarn_pct / 100.0) * 10)
        yarn_idx = max(0, min(9, yarn_idx))
        tension_idx = int(min(9, max(0, tension - 3.0)))
        if self.q_table is not None:
            if np.argmax(self.q_table[yarn_idx, tension_idx]) == 1:
                self.optimize_count += 1
                return {"action": "OPTIMIZE_TENSION", "msg": "âš¡ RLä¼˜åŒ–å¼ åŠ›"}
        return {"action": "MONITOR", "msg": "Optimal"}

# === Flask Server ä¿æŒä¸å˜ ===
app = Flask(__name__)
# å…è®¸å‰ç«¯è®¿é—®è¿™äº›æ•æ„Ÿ Header
CORS(app, expose_headers=["Content-Disposition", "Content-Length"])
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

@app.route('/')
def index(): return send_file('dashboard.html')

@app.route('/<path:filename>')
def serve_static(filename):
    """æä¾›é™æ€æ–‡ä»¶ï¼ˆPNGã€CSSç­‰ï¼‰"""
    if filename.endswith(('.png', '.jpg', '.jpeg', '.gif', '.ico', '.css', '.js')):
        return send_file(filename)
    return "Not Found", 404

@app.route('/api/status')
def get_status(): return jsonify(GLOBAL_STATE)

@app.route('/api/control', methods=['POST'])
def manual_control():
    try:
        data = request.json
        client_ip = data.get('ip')
        action = data.get('action')
        password = data.get('password') # [NEW] Auth Check

        if not client_ip or not action:
            return jsonify({"error": "Missing params"}), 400
        
        # Simple Hardcoded Auth
        if password != "admin123":
             print(f"ğŸ”’ [Security] Unauthorized control attempt from {client_ip} for {action}")
             return jsonify({"error": "Unauthorized"}), 401

        # Push to Queue
        device_type = data.get('type')
        queue_key = f"{client_ip}_{device_type}" if device_type else client_ip
        
        if queue_key not in GLOBAL_STATE['command_queues']:
            GLOBAL_STATE['command_queues'][queue_key] = []
        
        cmd = {"action": action, "params": data.get('params', {})}
        GLOBAL_STATE['command_queues'][queue_key].append(cmd)
        
        # Log
        add_system_log("MANUAL_CONTROL", f"User dispatched {action} to {client_ip}")
        
        return jsonify({"status": "queued", "target": client_ip, "action": action})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/devices/list')
def get_device_list():
    """
    è·å–è®¾å¤‡åˆ—è¡¨ï¼š
    1. å°è¯•ä»è¿œç¨‹ MONITOR åº“æŸ¥è¯¢çœŸå®è®¾å¤‡ã€‚
    2. åˆå¹¶å½“å‰å†…å­˜ä¸­å·²è¿æ¥çš„æ¨¡æ‹Ÿè®¾å¤‡ (GLOBAL_STATE)ã€‚
    """
    devices = set() # ä½¿ç”¨é›†åˆå»é‡

    # --- æ­¥éª¤ A: æŸ¥è¯¢è¿œç¨‹ InfluxDB (MONITOR_URL) ---
    try:
        if MONITOR_TOKEN:
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬åŠ ä¸Š try-exceptï¼Œé˜²æ­¢è¿œç¨‹è¿ä¸ä¸Šå¯¼è‡´æ•´ä¸ªæ¥å£æŠ¥é”™ï¼Œ
            # ä»è€Œå¯¼è‡´è¿æœ¬åœ°è®¾å¤‡éƒ½æ˜¾ç¤ºä¸å‡ºæ¥ã€‚
            try:
                client = InfluxDBClient(url=MONITOR_URL, token=MONITOR_TOKEN, org=MONITOR_ORG)
                query_api = client.query_api()
                
                # æŸ¥è¯¢è¿œç¨‹æ•°æ®åº“çš„ gateWayId æ ‡ç­¾ï¼ˆå®é™…å­—æ®µåï¼‰
                query = f'import "influxdata/influxdb/schema"\n schema.tagValues(bucket: "{MONITOR_BUCKET}", tag: "gateWayId")'
                
                tables = query_api.query(query)
                for table in tables:
                    for record in table.records:
                        val = record.get_value()
                        if val: devices.add(val)
                client.close()
                print(f"ğŸŒ [Device List] Found {len(devices)} remote devices.")
            except Exception as remote_e:
                print(f"âš ï¸ [Device List] è¿œç¨‹åº“æŸ¥è¯¢å¤±è´¥ (éè‡´å‘½): {remote_e}")
    except Exception as e:
        print(f"âš ï¸ [Device List] è¿œç¨‹è¿æ¥åˆå§‹åŒ–é”™è¯¯: {e}")

    # --- æ­¥éª¤ B: åˆå¹¶æœ¬åœ°æ¨¡æ‹Ÿè®¾å¤‡ (å…³é”®ä¿®å¤) ---
    # å³ä½¿è¿œç¨‹æŸ¥ä¸åˆ°ï¼Œè¿™é‡Œä¹Ÿèƒ½ä¿è¯æ˜¾ç¤ºä½ æ­£åœ¨è¿è¡Œçš„ Python æ¨¡æ‹Ÿå™¨
    try:
        local_count = 0
        for device_key, device_info in GLOBAL_STATE['devices'].items():
            # device_key æ ¼å¼é€šå¸¸æ˜¯ "IP_TYPE" æˆ–ç›´æ¥æ˜¯ IP
            # æˆ‘ä»¬ä¼˜å…ˆæå– device_info é‡Œçš„ 'ip'ï¼Œå¦‚æœæ²¡æœ‰åˆ™è§£æ key
            ip = device_info.get('ip')
            if not ip:
                ip = device_key.split('_')[0] # å°è¯•ä» key æå– IP
            
            if ip:
                devices.add(ip)
                local_count += 1
        print(f"ğŸ’» [Device List] Added {local_count} local simulation devices.")
    except Exception as local_e:
        print(f"âŒ [Device List] æœ¬åœ°åˆå¹¶é”™è¯¯: {local_e}")

    # --- æ­¥éª¤ C: æ ¼å¼åŒ–è¿”å› ---
    final_list = list(devices)
    final_list.sort()
    
    # å¦‚æœåˆ—è¡¨ä¸ºç©ºï¼Œè¿”å›ä¸€ä¸ªå‹å¥½çš„é”™è¯¯æç¤ºï¼Œè€Œä¸æ˜¯ç©ºåˆ—è¡¨ï¼Œæ–¹ä¾¿å‰ç«¯è°ƒè¯•
    if not final_list:
        print("âš ï¸ [Device List] No devices found in either Remote DB or Local Memory.")
    
    return jsonify(final_list)

@app.route('/api/devices/switch/<path:device_id>', methods=['POST'])
def switch_device(device_id):
    """åˆ‡æ¢å½“å‰ç›‘æ§çš„è®¾å¤‡ï¼Œå¹¶ç«‹å³åˆ·æ–°æ•°æ®"""
    GLOBAL_STATE['current_device'] = device_id
    add_system_log("DEVICE_SWITCH", f"å·²åˆ‡æ¢ç›‘æ§è®¾å¤‡è‡³ {device_id}")
    print(f"ğŸ”„ [Device Switch] Now monitoring: {device_id}")
    
    # === ç«‹å³æŸ¥è¯¢å¹¶æ¨é€æ•°æ® ===
    try:
        connector = InfluxConnector(MONITOR_URL, MONITOR_TOKEN, MONITOR_ORG, MONITOR_BUCKET)
        df = connector.query_recent_data(minutes=10, device_id=device_id)
        connector.close()
        
        if df is not None and not df.empty:
            latest = df.iloc[-1]
            
            # æå–ç”µå‹ç”µæµåŠŸç‡
            volts = 0
            if all(c in df.columns for c in ['ua', 'ub', 'uc']):
                volts = df[['ua', 'ub', 'uc']].iloc[-1].mean()
            
            amps = 0
            if all(c in df.columns for c in ['ia', 'ib', 'ic']):
                amps = df[['ia', 'ib', 'ic']].iloc[-1].mean()
            
            power_kw = 0
            if 'pt' in df.columns:
                power_kw = float(latest.get('pt', 0)) / 1000.0
            elif 'demand' in df.columns:
                power_kw = float(latest.get('demand', 0)) / 1000.0
            
            pf = float(latest.get('pft', 0))
            if pf > 1.0:
                pf = pf / 1000.0
            
            baseline_kw = power_kw * 1.15 if power_kw > 0.1 else None
            
            payload = {
                "power_kw": round(power_kw, 2),
                "baseline_kw": round(baseline_kw, 2) if baseline_kw else None,
                "voltage": round(volts, 1),
                "current": round(amps, 1),
                "pf": round(pf, 2),
                "idle_hours": 0,
                "forecast_peak_kw": None,
                "alerts": [{"msg": f"âœ… å·²åˆ‡æ¢è‡³ {device_id}", "level": "NOTICE", "confidence": "é«˜"}],
                "timestamp": datetime.now().strftime('%H:%M:%S')
            }
            
            socketio.emit('grid_monitor_update', payload)
            print(f"ğŸ“¡ [Immediate Push] Data sent for {device_id}")
            
    except Exception as e:
        print(f"âš ï¸ [Device Switch] Immediate query failed: {e}")
    
    return jsonify({"status": "ok", "device": device_id})

@app.route('/api/history')
def get_history():
    """è·å–è¿‡å»1å°æ—¶çš„èšåˆæ•°æ® (Device A + Device B)"""
    if not influx_client:
        return jsonify({"error": "InfluxDB not connected"}), 500

    query_api = influx_client.query_api()
    # æŸ¥è¯¢ Device A (current) å’Œ Device B (power)
    # ç®€å•èµ·è§ï¼Œä» "sensor_metrics" bucket å–æœ€è¿‘ 1h
    query = f'''
    from(bucket: "{INFLUX_BUCKET}")
      |> range(start: -1h)
      |> filter(fn: (r) => r["_measurement"] == "sensor_metrics")
      |> filter(fn: (r) => r["_field"] == "power_kw" or r["_field"] == "current_a")
      |> aggregateWindow(every: 1m, fn: mean, createEmpty: false)
      |> yield(name: "mean")
    '''
    try:
        tables = query_api.query(query, org=INFLUX_ORG)
        history_data = []
        for table in tables:
            for record in table.records:
                # ç®€å•èšåˆï¼šæŠŠæ‰€æœ‰è®¾å¤‡çš„ metric éƒ½ä¸¢è¿›å»å±•ç¤ºè¶‹åŠ¿
                history_data.append({
                    "time": record.get_time().isoformat(),
                    "value": record.get_value(),
                    "field": record.get_field()
                })
        return jsonify(history_data)
    except Exception as e:
        print(f"Query Error: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/settings', methods=['GET', 'POST'])
def handle_settings():
    if request.method == 'GET':
        return jsonify(settings.config)
    elif request.method == 'POST':
        data = request.json
        settings.update(data)
        return jsonify({"status": "updated", "config": settings.config})

@app.route('/api/control', methods=['POST'])
def handle_control():
    """
    æ¥æ”¶å‰ç«¯æ‰‹åŠ¨æŒ‡ä»¤
    Input: { "ip": "127.0.0.1", "action": "INJECT", "params": {} }
    """
    try:
        data = request.json
        target_ip = data.get('ip')
        action = data.get('action')
        params = data.get('params', {})
        
        if not target_ip or not action:
            return jsonify({"error": "Missing 'ip' or 'action'"}), 400
            
        # Initialize queue if not exists
        if target_ip not in GLOBAL_STATE['command_queues']:
            GLOBAL_STATE['command_queues'][target_ip] = []
            
        cmd = {"action": action, **params, "timestamp": time.time()}
        GLOBAL_STATE['command_queues'][target_ip].append(cmd)
        
        print(f"ğŸ® [Manual Control] Queued for {target_ip}: {action}")
        add_system_log("äººå·¥æŒ‡ä»¤", f"å·²ä¸‹å‘æŒ‡ä»¤ {action} åˆ°è®¾å¤‡ {target_ip}", details=cmd)
        
        return jsonify({"status": "queued", "queue_length": len(GLOBAL_STATE['command_queues'][target_ip])})
        
    except Exception as e:
        print(f"Control Error: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/export/events')
def export_events():
    if not mysql_db:
        return jsonify({"error": "Database not connected"}), 500
    
    events = mysql_db.fetch_events(limit=5000)
    if not events:
        return "No events found", 404
    
    import traceback
    try:
        # Convert to Excel
        print("ğŸ“Š [Export] Fetching events...")
        df = pd.DataFrame(events)
        print(f"ğŸ“Š [Export] DataFrame created: {len(df)} rows")
        
        # Reorder/Rename columns if needed
        if not df.empty:
            # Ensure correct column order/names
            cols = ['id', 'event_time', 'device_ip', 'device_type', 'action_type', 'message', 'details_json']
            # Filter only existing columns
            cols = [c for c in cols if c in df.columns]
            df = df[cols]
            
            # Ensure datetime is timezone-naive to avoid Excel errors
            if 'event_time' in df.columns:
                df['event_time'] = df['event_time'].astype(str)

        output = io.BytesIO()
        print("ğŸ“Š [Export] Writing to CSV...")
        # export to csv with utf-8-sig (BOM) for Excel compatibility
        df.to_csv(output, index=False, encoding='utf-8-sig')
        
        output.seek(0)
        print("âœ… [Export] Done.")
        
       # 1. è·å–æ–‡ä»¶ç²¾ç¡®å¤§å° (Bytes)
        file_size = output.getbuffer().nbytes

        # 2. ç”Ÿæˆå“åº”å¯¹è±¡ï¼Œä½†ä¸ç›´æ¥ return
        response = send_file(
            output,
            as_attachment=True,
            download_name='events_report.csv',
            mimetype='text/csv'
        )

        # 3. æ˜¾å¼æ·»åŠ  Content-Length å¤´
        # è¿™ä¹Ÿæ˜¯ä¸‹è½½å·¥å…·åˆ¤æ–­è¿›åº¦çš„å…³é”®
        response.headers["Content-Length"] = file_size
        
        # 4. æ˜¾å¼æ·»åŠ  Content-Disposition (åŒé‡ä¿é™©)
        # é˜²æ­¢ Flask ç‰ˆæœ¬å…¼å®¹é—®é¢˜å¯¼è‡´ download_name å¤±æ•ˆ
        response.headers["Content-Disposition"] = "attachment; filename=events_report.csv"

        # 5. æ·»åŠ  CORS æš´éœ²å¤´ (é˜²æ­¢å‰ç«¯ JS æ‹¿ä¸åˆ°æ–‡ä»¶å)
        response.headers["Access-Control-Expose-Headers"] = "Content-Disposition"

        return response
    except Exception as e:
        print(f"âŒ Export Error: {e}")
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

def start_http_server():
    print(f"ğŸŒ [Web API] å¯åŠ¨ (SocketIO port {HTTP_PORT})")
    socketio.run(app, host='0.0.0.0', port=HTTP_PORT, debug=False, use_reloader=False, allow_unsafe_werkzeug=True)

# --- æ–°å¢ 3: åˆå§‹åŒ–è¿œç¨‹æ•°æ®åº“è¿æ¥ä¸ Bucket ---
def init_influxdb():
    global influx_client, write_api
    print(f"â˜ï¸ æ­£åœ¨è¿æ¥è¿œç¨‹æ•°æ®åº“: {INFLUX_URL} ...")
    
    try:
        influx_client = InfluxDBClient(url=INFLUX_URL, token=INFLUX_TOKEN, org=INFLUX_ORG)
        
        # 1. æ£€æŸ¥å¹¶åˆ›å»º Bucket
        buckets_api = influx_client.buckets_api()
        existing_bucket = buckets_api.find_bucket_by_name(INFLUX_BUCKET)
        
        if existing_bucket:
            print(f"âœ… è¿œç¨‹ Bucket '{INFLUX_BUCKET}' å·²å­˜åœ¨ã€‚")
        else:
            print(f"ğŸ“¦ è¿œç¨‹ Bucket '{INFLUX_BUCKET}' ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...")
            buckets_api.create_bucket(bucket_name=INFLUX_BUCKET, org=INFLUX_ORG)
            print(f"âœ… Bucket '{INFLUX_BUCKET}' åˆ›å»ºæˆåŠŸï¼")

        # 2. åˆå§‹åŒ–å†™å…¥ API (ä½¿ç”¨å¼‚æ­¥æ‰¹é‡å†™å…¥ï¼Œé˜²æ­¢é˜»å¡ socket çº¿ç¨‹)
        write_api = influx_client.write_api(write_options=WriteOptions(batch_size=1, flush_interval=1000))
        print("ğŸš€ InfluxDB å†™å…¥é€šé“å·²å°±ç»ª")
        
    except Exception as e:
        print(f"âŒ è¿œç¨‹æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        print("   -> è¯·æ£€æŸ¥ IP æ˜¯å¦é€šç•…ï¼Œç«¯å£ 8086 æ˜¯å¦å¼€æ”¾ï¼ŒToken æ˜¯å¦æ­£ç¡®ã€‚")
        influx_client = None
        write_api = None

# Retry Helper
last_influx_retry = 0
def get_influx_writer():
    global write_api, last_influx_retry
    if write_api: 
        return write_api
    
    # Check cooldown (e.g., 30s)
    if time.time() - last_influx_retry < 30:
        return None
        
    last_influx_retry = time.time()
    print("ğŸ”„ [System] å°è¯•é‡è¿ InfluxDB...")
    init_influxdb()
    return write_api

# === Realtime Monitoring Loop ===
def run_monitoring_loop():
    print(f"ğŸ” [Monitoring] Connecting to Monitor DB at {MONITOR_URL}...")
    connector = InfluxConnector(MONITOR_URL, MONITOR_TOKEN, MONITOR_ORG, MONITOR_BUCKET)
    
    print("ğŸ§  [Monitoring] Loading Forecasting Model (LSTM)...")
    try:
        forecaster = LSTMForecaster()
    except Exception as e:
        print(f"âš ï¸ [Monitoring] Model load failed: {e}")
        forecaster = None

    # --- Initialize Baseline Predictor ---
    baseline_predictor = None
    if EnergyBaselinePredictor:
        try:
            baseline_predictor = EnergyBaselinePredictor()
            print("ğŸ§  [Monitoring] Baseline Predictor Loaded")
        except Exception as e:
            print(f"âš ï¸ [Monitoring] Baseline Predictor init failed: {e}")

    print("âœ… [Monitoring] Loop Started (60s interval)")
    
    while True:
        try:
            # 1. Fetch Data
            # Fetch last 24 hours (1440 min) to ensure accurate daily idle stats
            current_device = GLOBAL_STATE.get('current_device', 'energy*1*1')
            df = connector.query_recent_data(minutes=1440, device_id=current_device)
            
            if df is not None and not df.empty:
                # 2. Prepare Data
                df_kw = df.copy()
                if 'pt' in df_kw.columns:
                    df_kw['pt'] = df_kw['pt'] / 1000.0
                if 'demand' in df_kw.columns:
                    df_kw['demand'] = df_kw['demand'] / 1000.0

                # 3. Analyze
                optimizer = EnergyOptimizer(df_kw)
                idle_stats = optimizer.detect_idle_state(duration_minutes=15, resample_interval_minutes=1) 
                balance_stats = optimizer.analyze_phase_balance()
                pf_stats = optimizer.analyze_power_factor()
                
                # 4. Extract Metrics
                current_power_kw = 0
                if 'pt' in df_kw.columns: current_power_kw = df_kw['pt'].iloc[-1]
                elif 'demand' in df_kw.columns: current_power_kw = df_kw['demand'].iloc[-1]

                volts = 0
                if all(c in df.columns for c in ['ua', 'ub', 'uc']):
                    volts = df[['ua', 'ub', 'uc']].iloc[-1].mean()
                
                amps = 0
                if all(c in df.columns for c in ['ia', 'ib', 'ic']):
                    amps = df[['ia', 'ib', 'ic']].iloc[-1].mean()
                
                pf = 0
                if 'pft' in df.columns:
                    pf = df['pft'].iloc[-1]
                    if pf > 1.0: pf = pf / 1000.0

                # 5. Forecast
                pred_peak_kw = None
                if forecaster:
                    try:
                        pred_peak_watts = forecaster.predict_next_peak(df)
                        if pred_peak_watts is not None:
                            pred_peak_kw = pred_peak_watts / 1000.0
                    except Exception as e:
                        print(f"Forecast error: {e}")
                
                # 5.1 Calculate Dynamic Baseline
                baseline_kw = None
                
                # [MODIFIED] Strategy Change: User requested Baseline = 115% of Current Power
                # Previous ML-based approach:
                # if baseline_predictor:
                #     order = PRODUCTION_ORDERS.get("127.0.0.1", {})
                #     if order:
                #         try:
                #             baseline_kw = baseline_predictor.predict_baseline(...)
                #         except Exception as e: ...
                
                if current_power_kw > 0.1: # Only calculate if there is power
                     baseline_kw = current_power_kw * 1.15

                # 6. Build Alerts & Tips (Structured)
                alerts = []
                
                # A. Power Anomaly
                # DingTalk Config
                DINGTALK_WEBHOOK = os.getenv('DINGTALK_WEBHOOK', '') # User to provide in .env

                def send_dingtalk_alert(msg):
                    if not DINGTALK_WEBHOOK: return
                    try:
                        requests.post(DINGTALK_WEBHOOK, json={
                            "msgtype": "text",
                            "text": {"content": f"ğŸš¨ [å¾—é¹¿å±±èƒ½æºè­¦æŠ¥] {msg}"}
                        }, timeout=2)
                    except: pass

                if baseline_kw and current_power_kw > baseline_kw:
                    ratio = current_power_kw / baseline_kw
                    if ratio > 1.2:
                        msg = f"ğŸ”¥ èƒ½è€—ä¸¥é‡è¶…æ ‡: {current_power_kw:.1f}kW (>120%)"
                        alerts.append({"msg": msg, "level": "CRITICAL", "confidence": "é«˜"})
                        send_dingtalk_alert(msg) # [NEW] Webhook
                    elif ratio > 1.1:
                        alerts.append({"msg": f"âš ï¸ èƒ½è€—åé«˜: {current_power_kw:.1f}kW (>110%)", "level": "WARNING", "confidence": "ä¸­"})
                
                # B. Voltage Balance
                unbal = balance_stats.get('max_unbalance_percent', 0)
                if unbal > 25:
                     alerts.append({"msg": f"âš¡ ä¸‰ç›¸ä¸¥é‡ä¸å¹³: {unbal:.1f}%", "level": "CRITICAL", "confidence": "é«˜"})
                elif unbal > 15:
                     alerts.append({"msg": f"âš ï¸ ä¸‰ç›¸ä¸å¹³è¡¡: {unbal:.1f}%", "level": "WARNING", "confidence": "ä¸­"})

                # C. Power Factor
                avg_pf = pf_stats.get('avg_pf', 1.0)
                if avg_pf < 0.85:
                    alerts.append({"msg": f"ğŸ“‰ åŠŸç‡å› æ•°è¿‡ä½: {avg_pf:.2f}", "level": "WARNING", "confidence": "é«˜"})
                elif avg_pf < 0.90:
                    alerts.append({"msg": f"â„¹ï¸ åŠŸç‡å› æ•°éœ€ä¼˜åŒ–: {avg_pf:.2f}", "level": "NOTICE", "confidence": "ä½"})

                # D. Idle Detection
                idle_hrs = idle_stats.get('total_idle_hours', 0)
                if idle_hrs > 1.0:
                    alerts.append({"msg": f"ğŸ’¤ é•¿æ—¶é—´ç©ºè½¬: {idle_hrs:.1f}h", "level": "WARNING", "confidence": "é«˜"})
                elif idle_hrs > 0.2:
                    alerts.append({"msg": f"â„¹ï¸ è¯†åˆ«åˆ°é—´æ­‡ç©ºè½¬: {idle_hrs*60:.0f}min", "level": "NOTICE", "confidence": "ä¸­"})

                # E. Optimization Tips (If no critical alerts)
                if not any(a['level'] == 'CRITICAL' for a in alerts):
                     if baseline_kw and current_power_kw <= baseline_kw * 1.05:
                         alerts.insert(0, {"msg": "âœ… æœºå™¨èƒ½è€—æœªè¶…è¶ŠåŸºçº¿æ¨¡å‹ï¼Œèƒ½è€—æ­£å¸¸", "level": "NOTICE", "confidence": "é«˜"})
                     if avg_pf > 0.95:
                         alerts.append({"msg": "âœ… åŠŸç‡å› æ•°ä¼˜å¼‚ï¼Œæ— éœ€è¡¥å¿", "level": "NOTICE", "confidence": "é«˜"})
                     if unbal < 5:
                         alerts.append({"msg": "âœ… ä¸‰ç›¸å¹³è¡¡è‰¯å¥½", "level": "NOTICE", "confidence": "é«˜"})

                # 7. Broadcast
                payload = {
                    "power_kw": round(current_power_kw, 2),
                    "baseline_kw": baseline_kw,
                    "voltage": round(volts, 1),
                    "current": round(amps, 1),
                    "pf": round(pf, 2),
                    "idle_hours": round(idle_stats.get('total_idle_hours', 0), 2),
                    "forecast_peak_kw": round(pred_peak_kw, 2) if pred_peak_kw else None,
                    "alerts": alerts,
                    "timestamp": datetime.now().strftime('%H:%M:%S')
                }
                
                # Cache for AI
                GLOBAL_STATE['monitor_context'] = payload

                # print(f"ğŸ“¡ [Monitor] Emitting update: {payload}")
                socketio.emit('grid_monitor_update', payload)

        except Exception as e:
            print(f"âŒ [Monitor] Error: {e}")

        time.sleep(60)


# === æœåŠ¡å™¨ä¸»é€»è¾‘ ===
def handle_client(conn, addr):
    client_ip = addr[0]
    print(f"ğŸ”— æ–°è®¾å¤‡: {client_ip}")

    lub_ai = LubricationAI_RL()
    ten_ai = TensionAI_RL()
    
    # ... (åŸºçº¿åˆå§‹åŒ–ä¿æŒä¸å˜) ...
    baseline_power = 3.5 

    try:
        with conn:
            last_calc_time = time.time()
            while True:
                data = conn.recv(1024)
                if not data: break
                try:
                    sensor_data = json.loads(data.decode('utf-8'))
                except: continue

                d_type = sensor_data.get("device_type", "UNKNOWN")
                

                # --- æ–°å¢ 4: å°†æ•°æ®å†™å…¥è¿œç¨‹ InfluxDB (Safe & Lazy) ---
                writer = get_influx_writer()
                if writer:
                    try:
                        # åˆ›å»ºæ•°æ®ç‚¹
                        p = Point("sensor_metrics") \
                            .tag("device_ip", client_ip) \
                            .tag("device_type", d_type)
                        
                        # æ ¹æ®è®¾å¤‡ç±»å‹æ·»åŠ  Field
                        if d_type == "LUBRICATION_BOT":
                            p.field("current_a", float(sensor_data.get('current_a', 0)))
                            p.field("temperature_c", float(sensor_data.get('temperature_c', 0)))
                        elif d_type == "TENSION_BOT":
                            p.field("tension_g", float(sensor_data.get('tension', 0)))
                            p.field("yarn_pct", float(sensor_data.get('yarn_pct', 0)))
                            p.field("power_kw", float(sensor_data.get('power', 0)))
                        
                        # å†™å…¥
                        writer.write(bucket=INFLUX_BUCKET, org=INFLUX_ORG, record=p)
                    except Exception as ie:
                        print(f"âš ï¸ å†™å…¥å¤±è´¥: {ie}")
                        # If write fails, reset writer to force reconnect next time?
                        # write_api = None # Maybe too aggressive
                        pass

                # ... (åŸæœ‰çš„ GLOBAL_STATE æ›´æ–°é€»è¾‘ ä¿æŒä¸å˜) ...
                device_key = f"{client_ip}_{d_type}"
                GLOBAL_STATE['devices'][device_key] = {
                    "ip": client_ip, # [FIX] Add IP for frontend
                    "type": d_type,
                    "data": sensor_data,
                    "last_seen": time.time(),
                    "stats": {"inject_count": lub_ai.inject_count, "optimize_count": ten_ai.optimize_count}
                }
                # ... (åŸæœ‰çš„ U6da6æ»‘/å¼ åŠ› ä¸šåŠ¡é€»è¾‘ ä¿æŒä¸å˜) ...

                # ... (åŸæœ‰çš„ æ¶¦æ»‘/å¼ åŠ› ä¸šåŠ¡é€»è¾‘ ä¿æŒä¸å˜) ...
                
                # === åˆ†æ”¯ 1: æ¶¦æ»‘æœºå™¨äºº ===
                if d_type == "LUBRICATION_BOT":
                    # --- 1. è·å–æœºå™¨è¿è¡ŒçŠ¶æ€ ---
                    curr_amp = sensor_data.get('current_a', 0.0)
                    # è®¾å®šä¸€ä¸ªé˜ˆå€¼ï¼Œæ¯”å¦‚ 1.0Aï¼Œä½äºæ­¤å€¼è®¤ä¸ºæœºå™¨å¾…æœº/åœè½¦
                    is_running = curr_amp > 1.0 

                    # --- 2. è®¡ç®—æ—¶é—´å·® ---
                    now = time.time()
                    dt_seconds = (now - last_calc_time)
                    last_calc_time = now 
                    
                    # --- 3. ä¿®æ­£åçš„åŸºçº¿æ¶ˆè€—è®¡ç®— ---
                    # ã€ä¿®æ”¹ç‚¹ã€‘ï¼šåªæœ‰å½“æœºå™¨åœ¨è¿è½¬æ—¶ï¼Œæ‰è®¡ç®—åŸºçº¿çš„ç†è®ºæ¶ˆè€—
                    # å¦‚æœæœºå™¨åœäº†ï¼Œè€æœºå™¨ä¹Ÿä¸å–·æ²¹ï¼Œæ‰€ä»¥æ²¡æœ‰äº§ç”Ÿâ€œèŠ‚æ²¹â€
                    if is_running:
                        baseline_rate = settings.get('INJECT_VOLUME_LTERS') / settings.get('BASELINE_INJECT_INTERVAL')
                        period_baseline_usage = baseline_rate * dt_seconds
                    else:
                        period_baseline_usage = 0.0

                    saved_oil = period_baseline_usage

                    # --- 4. æ‰§è¡Œå†³ç­– (äººå·¥ä¼˜å…ˆ) ---
                    # Check for manual command
                    manual_cmd = None
                    # Use device_key (ip_type) which solves collision
                    if device_key in GLOBAL_STATE['command_queues'] and GLOBAL_STATE['command_queues'][device_key]:
                         manual_cmd = GLOBAL_STATE['command_queues'][device_key].pop(0)
                         print(f"ğŸ® [Override] æ¶¦æ»‘æœº {device_key} æ‰§è¡Œäººå·¥æŒ‡ä»¤: {manual_cmd['action']}")
                    
                    # FALLBACK: Try IP only (legacy or generic broadcast)
                    elif client_ip in GLOBAL_STATE['command_queues'] and GLOBAL_STATE['command_queues'][client_ip]:
                         manual_cmd = GLOBAL_STATE['command_queues'][client_ip].pop(0)
                         print(f"ğŸ® [Override] æ¶¦æ»‘æœº {client_ip} æ‰§è¡Œå¹¿æ’­æŒ‡ä»¤: {manual_cmd['action']}")

                    if manual_cmd:
                        result = manual_cmd
                        # Ensure msg exists
                        if 'msg' not in result: result['msg'] = f"Manual Control: {manual_cmd['action']}"
                    else:
                        # å³ä½¿åœè½¦ä¹Ÿå¯ä»¥è®©AIåˆ†æï¼ˆä¸ºäº†ç›‘æ§æ¸©åº¦ï¼‰ï¼Œä½†é€šå¸¸AIä¹Ÿä¼šè¿”å›MONITOR
                        result = lub_ai.analyze(sensor_data)
                    
                    if result:
                        response = result
                        if result["action"] == "INJECT":
                            # å¦‚æœ RL å†³å®šå–·æ²¹ï¼Œåˆ™æ‰£é™¤èŠ‚çœé‡ (å³å®é™…æ¶ˆè€—äº†)
                            saved_oil -= settings.get('AI_INJECT_VOLUME')
                            # ã€å¯é€‰ã€‘å¯ä»¥åœ¨è¿™é‡Œå¼ºåˆ¶å¢åŠ ä¸€ä¸ªç‰©ç†å†·å´ï¼Œé˜²æ­¢AIè¿ç»­è¯¯åˆ¤
                            lub_ai.force_cooldown(5) # ä¾‹å¦‚å¼ºåˆ¶å†·å´10åˆ†é’Ÿ
                            print(f"[æ¶¦æ»‘ {addr}] {result['msg']}")
                            
                            # Log Event
                            is_manual = (manual_cmd is not None)
                            add_system_log(
                                "äººå·¥å–·æ²¹" if is_manual else "è‡ªåŠ¨å–·æ²¹", 
                                "æ”¶åˆ°äººå·¥å¼ºåˆ¶æ³¨æ²¹æŒ‡ä»¤" if is_manual else "æ£€æµ‹åˆ°æ¸©åº¦å’Œç”µæµå‡é«˜ï¼Œè¶…è¿‡å¼ºåŒ–å­¦ä¹ æœ€ä¼˜åŸºçº¿ï¼Œè‡ªåŠ¨æ‰§è¡Œå–·æ²¹æ“ä½œ",
                                {"current": f"{curr_amp:.2f}A", "temp": f"{sensor_data.get('temperature_c',0):.1f}Â°C"},
                                device_ip=client_ip,
                                device_type=d_type
                            )
                    
                    # --- 5. æ›´æ–°å…¨å±€ç»Ÿè®¡ ---
                    GLOBAL_STATE['energy_stats']['total_savings_oil_liters'] += saved_oil
                    GLOBAL_STATE['energy_stats']['total_savings_cost'] += (saved_oil * settings.get('OIL_PRICE'))


                # === åˆ†æ”¯ 2: å¼ åŠ›æœºå™¨äºº (é›†æˆåŸºçº¿ + RL) ===
                elif d_type == "TENSION_BOT":
                    current_power = sensor_data.get('power', 0)
                    
                    # [MODIFIED] Dynamic Baseline for Savings Calculation
                    # Ensure baseline is always relavtive to current usage for demo purposes
                    if current_power > 0.1:
                        baseline_power = current_power * 1.15
                    else:
                        baseline_power = 0.0

                    # --- æˆæœ¬è®¡ç®—é€»è¾‘ (ç´¯è®¡èŠ‚èƒ½) ---
                    if baseline_power:
                        now = time.time()
                        dt_hours = (now - last_calc_time) / 3600.0
                        last_calc_time = now
                        
                        # åªæœ‰å½“å®é™…åŠŸè€—å°äºåŸºçº¿æ—¶ï¼Œæ‰ç®—ä½œ"èŠ‚èƒ½"
                        # å¦‚æœå®é™…åŠŸè€—å¤§äºåŸºçº¿ï¼Œè¯´æ˜å¯èƒ½å­˜åœ¨æµªè´¹æˆ–æ•…éšœï¼Œè¿™é‡Œæš‚ä¸æ‰£å‡æ”¶ç›Šï¼Œåªç´¯è®¡æ­£å‘æ”¶ç›Š
                        saved_power = max(0, baseline_power - current_power)
                        saved_kwh = saved_power * dt_hours
                        saved_cost = saved_kwh * settings.get('ELECTRICITY_PRICE')
                        
                        GLOBAL_STATE['energy_stats']['total_savings_kwh'] += saved_kwh
                        GLOBAL_STATE['energy_stats']['total_savings_elec_cost'] += saved_cost
                        GLOBAL_STATE['energy_stats']['total_savings_cost'] += saved_cost
                        GLOBAL_STATE['energy_stats']['current_total_power'] = current_power # ç®€åŒ–ï¼šåªæ˜¾ç¤ºå½“å‰çš„
                        GLOBAL_STATE['energy_stats']['baseline_total_power'] = baseline_power

                    # --- æ­¥éª¤ A: åŸºçº¿å¼‚å¸¸æ£€æµ‹ (Rule-based Safety) ---
                    # å¦‚æœè®¡ç®—å‡ºäº†åŸºçº¿ï¼Œå…ˆæ£€æŸ¥æ˜¯å¦ä¸¥é‡è¶…æ ‡
                    is_serious_fault = False
                    if baseline_power:
                        diff_pct = (
                            (current_power - baseline_power) / baseline_power) * 100
                        # é˜ˆå€¼ï¼šå¦‚æœè¶…æ ‡ 20%ï¼Œè¿™è‚¯å®šä¸æ˜¯å¼ åŠ›é—®é¢˜ï¼Œè€Œæ˜¯æœºå™¨å¡æ­»æˆ–åäº†
                        if diff_pct > 20:
                            is_serious_fault = True
                            response = {
                                "action": "ALARM_STOP",
                                "msg": f"ğŸš¨ [ä¸¥é‡å¼‚å¸¸] å®æµ‹{current_power}kW è¿œè¶…åŸºçº¿{baseline_power}kW (+{diff_pct:.1f}%)"
                            }
                            print(
                                f"\033[91m[å¼ åŠ› {addr}] {response['msg']}\033[0m")

                    # --- æ­¥éª¤ B: RL èŠ‚èƒ½ä¼˜åŒ– ---
                    # åªæœ‰åœ¨æ²¡æœ‰ä¸¥é‡æ•…éšœæ—¶ï¼Œæ‰è®© RL ä»‹å…¥å¾®è°ƒ
                    if not is_serious_fault:
                        # Check for manual command
                        manual_cmd = None
                        # Use device_key (ip_type) which solves collision
                        if device_key in GLOBAL_STATE['command_queues'] and GLOBAL_STATE['command_queues'][device_key]:
                             manual_cmd = GLOBAL_STATE['command_queues'][device_key].pop(0)
                        elif client_ip in GLOBAL_STATE['command_queues'] and GLOBAL_STATE['command_queues'][client_ip]:
                             manual_cmd = GLOBAL_STATE['command_queues'][client_ip].pop(0)
                        
                        if manual_cmd:
                            result = manual_cmd
                            if 'msg' not in result: result['msg'] = f"Manual: {manual_cmd['action']}"
                        else:
                            result = ten_ai.analyze(sensor_data)
                            
                        response = result

                        # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬å°†åŸºçº¿ä¿¡æ¯é™„åŠ åˆ° Monitor æ¶ˆæ¯é‡Œ
                        if response["action"] == "MONITOR" and baseline_power:
                            diff_pct = (
                                (current_power - baseline_power) / baseline_power) * 100
                            response["msg"] += f" (åå·® {diff_pct:.1f}%)"

                        if result["action"] == "OPTIMIZE_TENSION":
                            print(f"[å¼ åŠ› {addr}] {result['msg']}")
                            # Log Event for specific tension conditions (simulation)
                            if sensor_data.get('tension', 0) > 10: # Example threshold
                                 add_system_log(
                                    "æ›´æ¢çº¿ç›˜",
                                    "æ£€æµ‹åˆ°ç”µæµçº¿ç›˜å¼ åŠ›å‡é«˜ï¼Œå·²é€šçŸ¥ç»´æŠ¤äººå‘˜åŠæ—¶æ›´æ¢çº¿ç›˜",
                                    {"tension": f"{sensor_data.get('tension',0):.1f}g", "current": f"{current_power:.2f}kW"},
                                    device_ip=client_ip,
                                    device_type=d_type
                                )
                    # å¦‚æœæœ‰ä¸¥é‡æ•…éšœï¼Œresponseå·²ç»è®¾ç½®ä¸ºALARM_STOPï¼Œæ— éœ€é¢å¤–æ“ä½œ
                    # å¦‚æœæœ‰ä¸¥é‡æ•…éšœï¼Œresponseå·²ç»è®¾ç½®ä¸ºALARM_STOPï¼Œæ— éœ€é¢å¤–æ“ä½œ

                else:
                    response = {"action": "ERROR", "msg": "Unknown Device"}

                # --- [FIX] åœ¨AIå†³ç­–åæ›´æ–°è®¾å¤‡çŠ¶æ€å¹¶æ¨é€ï¼Œç¡®ä¿ action å­—æ®µæ­£ç¡® ---
                # å°† action åˆå¹¶åˆ° sensor_data ä¸­
                sensor_data['action'] = response.get('action', 'MONITOR')
                
                # æ›´æ–°å…¨å±€çŠ¶æ€
                GLOBAL_STATE['devices'][device_key] = {
                    "ip": client_ip,
                    "type": d_type,
                    "data": sensor_data,
                    "last_seen": time.time(),
                    "stats": {"inject_count": lub_ai.inject_count, "optimize_count": ten_ai.optimize_count}
                }
                
                # WebSocket æ¨é€
                socketio.emit('device_update', GLOBAL_STATE['devices'][device_key])
                socketio.emit('stats_update', GLOBAL_STATE['energy_stats'])

                conn.sendall(json.dumps(response).encode('utf-8'))

    except Exception as e:
        print(f"âŒ è¿æ¥æ–­å¼€ {addr}: {e}")
    finally:
        device_key = f"{client_ip}_{d_type}" if 'd_type' in locals() else client_ip
        if device_key in GLOBAL_STATE['devices']:
            del GLOBAL_STATE['devices'][device_key]

@app.route('/api/ask_ai', methods=['POST'])
def ask_ai():
    try:
        data = request.json
        user_question = data.get('question', '')
        
        # 1. Gather Context
        stats = GLOBAL_STATE.get('energy_stats', {})
        total_kwh = stats.get('total_savings_kwh', 0)
        total_money = stats.get('total_savings_cost', 0)
        
        # Get Monitor Data
        mon_ctx = GLOBAL_STATE.get('monitor_context', {})
        alerts = mon_ctx.get('alerts', [])
        idle_hours = mon_ctx.get('idle_hours', 0)
        curr_pwr = mon_ctx.get('power_kw', stats.get('current_total_power', 0))
        perf = mon_ctx.get('pf', 0)
        
        alerts_str = ", ".join(alerts) if alerts else "None"

        context_str = f"""
        System Status:
        - Total Energy Saved: {total_kwh:.2f} kWh
        - Total Money Saved: {total_money:.2f} CNY
        - Current Actual Power: {curr_pwr:.2f} kW
        - Power Factor: {perf}
        - Idle Hours (24h): {idle_hours} h
        - Active Alerts: {alerts_str}
        """
        
        # 2. Call Qwen API
        url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {QWEN_API_KEY}"
        }
        body = {
            "model": "qwen-turbo",
            "input": {
                "messages": [
                    {"role": "system", "content": "You are an intelligent energy optimization assistant for a textile factory. Answer concisely based on the system status provided."},
                    {"role": "user", "content": f"Context: {context_str}\n\nQuestion: {user_question}"}
                ]
            }
        }
        
        response = requests.post(url, headers=headers, json=body)
        res_json = response.json()
        
        if response.status_code == 200 and 'output' in res_json:
            ai_text = res_json['output']['text']
            return jsonify({"answer": ai_text})
        else:
            print(f"Qwen Error: {res_json}")
            return jsonify({"answer": "Sorry, I could not connect to the AI service right now."}), 500
            
    except Exception as e:
        print(f"AI Error: {e}")
        return jsonify({"answer": f"Error: {str(e)}"}), 500

@socketio.on('connect')
def handle_connect():
    # Emit history logs
    # Send logs in reverse order (oldest first) so frontend can just append? 
    # Or send list and let frontend handle it. Sending list is standard.
    socketio.emit('system_log_history', GLOBAL_STATE['logs'])

def start_server():
    # å¯åŠ¨å‰åˆå§‹åŒ–æ•°æ®åº“
    init_influxdb() 
    
    print(f"âœ… æœåŠ¡å¯åŠ¨ (RL + Remote DB)")
    
    # å¯åŠ¨ Monitor çº¿ç¨‹
    monitor_thread = threading.Thread(target=run_monitoring_loop)
    monitor_thread.daemon = True
    monitor_thread.start()

    http_thread = threading.Thread(target=start_http_server)
    http_thread.daemon = True
    http_thread.start()
    
    # [NEW] Init MySQL
    global mysql_db
    mysql_db = MySQLDatabase(MYSQL_HOST, MYSQL_USER, MYSQL_PASS, MYSQL_DB)

    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    server.bind((HOST, PORT))
    server.listen()
    server.settimeout(1.0)
    
    print(f"ğŸ“¡ TCP ç›‘å¬: {HOST}:{PORT}")
    try:
        while True:
            try:
                conn, addr = server.accept()
                thread = threading.Thread(target=handle_client, args=(conn, addr))
                thread.daemon = True
                thread.start()
            except socket.timeout:
                continue
    except KeyboardInterrupt:
        print("åœæ­¢æœåŠ¡...")
    finally:
        server.close()

if __name__ == "__main__":
    start_server()