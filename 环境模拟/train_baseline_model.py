import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
import joblib

# === 1. æ¨¡æ‹Ÿå†å²ç”Ÿäº§æ•°æ® (å®é™…åœºæ™¯ä¸­ï¼Œè¿™æ˜¯ä»ä½ çš„æ•°æ®åº“è¯»å–çš„ CSV) ===


def generate_mock_data(n_samples=1000):
    np.random.seed(42)

    data = []
    yarns = ['Nylon', 'Spandex', 'Polyester']     # é”¦çº¶, æ°¨çº¶, æ¶¤çº¶
    structures = ['Plain', 'Rib', 'Jacquard']     # å¹³çº¹, ç½—çº¹, æèŠ±

    for _ in range(n_samples):
        # éšæœºç”Ÿæˆå·¥è‰ºå‚æ•°
        diameter = np.random.choice([14, 28, 30, 34])
        needles = int(diameter * np.random.uniform(20, 30) * 3)  # ä¼°ç®—é’ˆæ•°
        yarn = np.random.choice(yarns)
        struct = np.random.choice(structures)
        rpm = np.random.uniform(15, 30)  # å»ºè®®åŠ å…¥è½¬é€Ÿ

        # --- æ¨¡æ‹Ÿç‰©ç†è§„å¾‹ (ç”Ÿæˆ Label: Power) ---
        # åŸºç¡€åŠŸç‡
        base_power = 2.0
        # ç­’å¾„è¶Šå¤§ã€é’ˆæ•°è¶Šå¤šï¼ŒåŠŸç‡è¶Šå¤§
        hw_factor = (diameter / 14.0) * (needles / 2000.0)
        # çº±çº¿æ‘©æ“¦ç³»æ•°: æ¶¤çº¶ > é”¦çº¶ > æ°¨çº¶ (å‡è®¾)
        yarn_factor = {'Polyester': 1.2, 'Nylon': 1.1, 'Spandex': 1.0}[yarn]
        # ç»“æ„å¤æ‚åº¦: æèŠ± > ç½—çº¹ > å¹³çº¹
        struct_factor = {'Jacquard': 1.5, 'Rib': 1.2, 'Plain': 1.0}[struct]
        # é€Ÿåº¦å½±å“: åŠŸç‡ä¸é€Ÿåº¦å¤§è‡´æˆæ­£æ¯”
        speed_factor = rpm / 20.0

        # æœ€ç»ˆåŠŸç‡ = åŸºç¡€ * ç¡¬ä»¶ * çº±çº¿ * ç»“æ„ * é€Ÿåº¦ + éšæœºæ³¢åŠ¨(å™ªå£°)
        power = base_power * hw_factor * yarn_factor * struct_factor * speed_factor
        power += np.random.normal(0, 0.2)  # æ·»åŠ ä¸€ç‚¹ç°å®ä¸–ç•Œçš„å™ªå£°

        data.append([diameter, needles, yarn, struct, rpm, round(power, 2)])

    df = pd.DataFrame(
        data, columns=['diameter', 'needles', 'yarn', 'structure', 'rpm', 'power'])
    return df

# === 2. è®­ç»ƒæ¨¡å‹ ===


def train_model():
    print("ğŸ“Š æ­£åœ¨ç”Ÿæˆå¹¶åŠ è½½è®­ç»ƒæ•°æ®...")
    df = generate_mock_data(2000)

    # ç‰¹å¾é¢„å¤„ç†ï¼šOne-Hot ç¼–ç 
    # å°† yarn å’Œ structure è½¬æ¢ä¸ºæ•°å€¼åˆ— (ä¾‹å¦‚ yarn_Nylon, structure_Rib)
    df_encoded = pd.get_dummies(df, columns=['yarn', 'structure'])

    # å®šä¹‰ç‰¹å¾ (X) å’Œ ç›®æ ‡ (y)
    X = df_encoded.drop('power', axis=1)
    y = df_encoded['power']

    # ä¿å­˜åˆ—åï¼Œè¿™éå¸¸é‡è¦ï¼é¢„æµ‹æ—¶è¾“å…¥æ•°æ®çš„åˆ—é¡ºåºå¿…é¡»å’Œè®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´
    feature_columns = X.columns.tolist()
    joblib.dump(feature_columns, 'model_columns.pkl')

    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42)

    # åˆå§‹åŒ–éšæœºæ£®æ—å›å½’å™¨
    model = RandomForestRegressor(n_estimators=100, random_state=42)

    print("ğŸš€ å¼€å§‹è®­ç»ƒåŸºçº¿æ¨¡å‹...")
    model.fit(X_train, y_train)

    # è¯„ä¼°
    predictions = model.predict(X_test)
    mae = mean_absolute_error(y_test, predictions)
    print(f"âœ… è®­ç»ƒå®Œæˆï¼å¹³å‡é¢„æµ‹è¯¯å·® (MAE): {mae:.3f} kW")
    print(f"   (æ„å‘³ç€æ¨¡å‹é¢„æµ‹çš„åŸºçº¿å€¼ä¸ç†è®ºå€¼å¹³å‡åªå·® {mae*1000:.1f} ç“¦)")

    # ä¿å­˜æ¨¡å‹
    joblib.dump(model, 'energy_baseline_model.pkl')
    print("ğŸ’¾ æ¨¡å‹å·²ä¿å­˜ä¸º energy_baseline_model.pkl")


if __name__ == "__main__":
    train_model()
