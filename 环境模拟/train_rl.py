import numpy as np
import pickle
from env_sim import OilEnvironment

# Q-Table: 10ç§ç”µæµçŠ¶æ€ x 10ç§æ¸©åº¦çŠ¶æ€ x 2ç§åŠ¨ä½œ(å–·/ä¸å–·)
q_table = np.zeros((10, 10, 2))

# è¶…å‚æ•°
epsilon = 0.9   # æ¢ç´¢ç‡ (å‰æœŸå¤šçè¯•ï¼ŒåæœŸå¤šåˆ©ç”¨)
alpha = 0.1     # å­¦ä¹ ç‡
gamma = 0.9     # æŠ˜æ‰£å› å­ (çœ‹é‡é•¿è¿œåˆ©ç›Š)
EPISODES = 5000

env = OilEnvironment()

print("ğŸš€ å¼€å§‹å¼ºåŒ–å­¦ä¹ è®­ç»ƒ...")

for episode in range(EPISODES):
    state = env.reset()  # state is (current_idx, temp_idx)
    done = False

    # éšç€è®­ç»ƒè¿›è¡Œï¼Œå‡å°‘çè¯•çš„æ¦‚ç‡ (Epsilon Decay)
    if epsilon > 0.1:
        epsilon -= 0.0002

    while not done:
        # 1. é€‰æ‹©åŠ¨ä½œ (Epsilon-Greedy)
        if np.random.uniform(0, 1) < epsilon:
            action = np.random.choice([0, 1])  # æ¢ç´¢ï¼šéšæœºè¯•
        else:
            action = np.argmax(q_table[state[0], state[1]])  # åˆ©ç”¨ï¼šé€‰ç›®å‰æœ€å¥½çš„

        # 2. ä¸ç¯å¢ƒäº¤äº’
        next_state, reward, done = env.step(action)

        # 3. æ›´æ–° Q-Table (è´å°”æ›¼æ–¹ç¨‹)
        # Q(S,A) = Q(S,A) + alpha * [R + gamma * max(Q(S',a)) - Q(S,A)]
        old_value = q_table[state[0], state[1], action]
        next_max = np.max(q_table[next_state[0], next_state[1]])

        new_value = old_value + alpha * (reward + gamma * next_max - old_value)
        q_table[state[0], state[1], action] = new_value

        state = next_state

    if episode % 500 == 0:
        print(f"Episode {episode}: å‰©ä½™ Epsilon {epsilon:.3f}")

# ä¿å­˜è®­ç»ƒå¥½çš„å¤§è„‘
with open("q_brain.pkl", "wb") as f:
    pickle.dump(q_table, f)

print("âœ… è®­ç»ƒå®Œæˆï¼æ¨¡å‹å·²ä¿å­˜ä¸º q_brain.pkl")
# æ‰“å°ä¸€éƒ¨åˆ†ç­–ç•¥çœ‹çœ‹
print("\n--- ç­–ç•¥é¢„è§ˆ (éƒ¨åˆ†) ---")
print("å½“ç”µæµå¾ˆé«˜(Idx=8), æ¸©åº¦å¾ˆé«˜(Idx=8)æ—¶ ->",
      "å–·æ²¹" if np.argmax(q_table[8, 8]) == 1 else "ä¸å–·")
print("å½“ç”µæµæ­£å¸¸(Idx=1), æ¸©åº¦æ­£å¸¸(Idx=1)æ—¶ ->",
      "å–·æ²¹" if np.argmax(q_table[1, 1]) == 1 else "ä¸å–·")
