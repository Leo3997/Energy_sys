import numpy as np
import pickle
from env_tension_sim import TensionEnvironment

# Q-Table: 10ç§çº±çº¿çŠ¶æ€ x 10ç§å¼ åŠ›çŠ¶æ€ x 2ç§åŠ¨ä½œ
q_table = np.zeros((10, 10, 2))

# å‚æ•°
epsilon = 0.9
alpha = 0.1
gamma = 0.95
EPISODES = 5000

env = TensionEnvironment()

print("ğŸ§µ [å¼ åŠ›ä¼˜åŒ–] å¼€å§‹ RL è®­ç»ƒ...")

for episode in range(EPISODES):
    state = env.reset()
    done = False

    # è¡°å‡æ¢ç´¢ç‡
    if epsilon > 0.05:
        epsilon -= 0.0002

    while not done:
        # 1. é€‰åŠ¨ä½œ
        if np.random.uniform(0, 1) < epsilon:
            action = np.random.choice([0, 1])
        else:
            action = np.argmax(q_table[state[0], state[1]])

        # 2. äº¤äº’
        next_state, reward, done = env.step(action)

        # 3. å­¦ä¹  (è´å°”æ›¼æ–¹ç¨‹)
        old_val = q_table[state[0], state[1], action]
        next_max = np.max(q_table[next_state[0], next_state[1]])
        new_val = old_val + alpha * (reward + gamma * next_max - old_val)
        q_table[state[0], state[1], action] = new_val

        state = next_state

# ä¿å­˜æ¨¡å‹
with open("tension_q_brain.pkl", "wb") as f:
    pickle.dump(q_table, f)

print("âœ… æ¨¡å‹å·²ä¿å­˜ä¸º tension_q_brain.pkl")

# --- éªŒè¯ä¸€ä¸‹ AI å­¦åˆ°äº†ä»€ä¹ˆ ---
print("\n--- AI ç­–ç•¥é¢„è§ˆ ---")
# çœ‹çœ‹çº±çº¿å……è¶³(çŠ¶æ€9)ä¸”å¼ åŠ›æ­£å¸¸(çŠ¶æ€0)æ—¶ï¼Œå®ƒæ€ä¹ˆé€‰
act_normal = np.argmax(q_table[9, 0])
print(f"çº±çº¿å……è¶³(100%), å¼ åŠ›ä½ -> {'ğŸ”´ å¿…é¡»æ¢ç­’' if act_normal==1 else 'ğŸŸ¢ ç»§ç»­è¿è¡Œ'}")

# çœ‹çœ‹çº±çº¿å¿«æ²¡äº†(çŠ¶æ€1)ä¸”å¼ åŠ›æé«˜(çŠ¶æ€8)æ—¶ï¼Œå®ƒæ€ä¹ˆé€‰
act_danger = np.argmax(q_table[1, 8])
print(f"çº±çº¿å‘Šæ€¥(10%), å¼ åŠ›é«˜ -> {'ğŸ”´ å¿…é¡»æ¢ç­’' if act_danger==1 else 'ğŸŸ¢ ç»§ç»­è¿è¡Œ'}")
